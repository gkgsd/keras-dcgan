{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n",
      "Using gpu device 0: GeForce GTX TITAN X (CNMeM is disabled, cuDNN 5004)\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "import sys\n",
    "sys.path.insert(0, '../utils/')\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2, time, os, h5py, tqdm\n",
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils, generic_utils\n",
    "\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "from theano.sandbox.cuda.dnn import dnn_conv\n",
    "\n",
    "from lib import activations\n",
    "from lib import updates\n",
    "from lib import inits\n",
    "from lib.vis import color_grid_vis\n",
    "from lib.rng import py_rng, np_rng\n",
    "from lib.ops import batchnorm, conv_cond_concat, deconv, dropout, l2normalize\n",
    "from lib.theano_utils import floatX, sharedX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualizeimages(images,figname=None,showflag=True):\n",
    "    images = (np.rint((images+1.)*127.5)).astype(np.uint8)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    sz = images.shape\n",
    "    figlen = np.floor(np.sqrt(sz[0]))\n",
    "    for ii in range(int(figlen*figlen)):\n",
    "        ax = plt.subplot(figlen, figlen, ii+1)\n",
    "        img = images[ii]\n",
    "        img = np.transpose(img,[1,2,0])\n",
    "        plt.imshow(img)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    if figname is not None:\n",
    "        plt.savefig(figname,format='pdf')\n",
    "    if showflag:\n",
    "        plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "## Load the face dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_dataset_base = '/iccluster_data/bjin/Dcgan/Celeba/'\n",
    "path_dataset = '/iccluster_data/bjin/Dcgan/Celeba/img_align_celeba/'\n",
    "\n",
    "if not os.path.isfile(path_dataset_base + 'faces.hdf5'):\n",
    "    files = [x for x in os.listdir(path_dataset) if os.path.isfile(path_dataset + x)]\n",
    "    n_files = len(files)\n",
    "    hf = h5py.File(path_dataset_base + 'faces.hdf5','w')\n",
    "    images_hf = hf.create_dataset(\"images\", (n_files,3,64,64), dtype=np.float32, maxshape=(None,3,64,64))\n",
    "\n",
    "    images = np.zeros([n_files,3,64,64],dtype=np.float32)\n",
    "    for i in tqdm(range(n_files)):\n",
    "        filename = files[i]\n",
    "        img = cv2.imread(path_dataset + filename)\n",
    "        img = img[40:178,30:168,:]\n",
    "        img = cv2.resize(img,(64,64))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = np.transpose(img,[2,0,1]).astype(np.float32)\n",
    "        img = img / 127.5 - 1.\n",
    "        images[i] = img\n",
    "\n",
    "    print images.shape\n",
    "    images_hf[...] = images\n",
    "    hf.close()\n",
    "    \n",
    "hf = h5py.File(path_dataset_base + 'faces.hdf5','r')\n",
    "images = hf['images'][:]\n",
    "print images.shape, images.dtype\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the AVA aesthetics dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "path_dataset = '/iccluster_data/bjin/AVA_dataset/'\n",
    "\n",
    "if not os.path.isfile(path_dataset + 'AVAdataset_64.hdf5'):\n",
    "    print 'generating images'\n",
    "    hf = h5py.File(path_dataset + 'AVAdataset_224.hdf5','r')\n",
    "\n",
    "    images_train = hf['images_train']\n",
    "    scores_train = hf['scores_train']\n",
    "    images_val_even = hf['images_test_even']\n",
    "    scores_val_even = hf['scores_test_even']\n",
    "    images_val_uneven = hf['images_test_uneven']\n",
    "    scores_val_uneven = hf['scores_test_uneven']\n",
    "    \n",
    "    images = np.concatenate((images_train,images_val_even,images_val_uneven),axis=0)\n",
    "    scores = np.concatenate((scores_train,scores_val_even,scores_val_uneven))\n",
    "    hf.close()\n",
    "    \n",
    "    images_new = np.zeros([len(images),3,64,64],dtype=np.float32)\n",
    "    for i in range(len(images)):\n",
    "        img = images[i]\n",
    "        img = np.transpose(img,[1,2,0])\n",
    "        img = cv2.resize(img,(64,64))\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        img = np.transpose(img,[2,0,1]).astype(np.float32)\n",
    "        img = img / 127.5 - 1.\n",
    "        images_new[i] = img\n",
    "    print images_new.shape, np.max(img),np.min(img)\n",
    "    \n",
    "    hf = h5py.File(path_dataset + 'AVAdataset_64.hdf5','w')\n",
    "    images_hf = hf.create_dataset(\"images\", (len(images),3,64,64), dtype=np.float32, maxshape=(None,3,64,64))\n",
    "    images_hf[...] = images_new\n",
    "    hf.close()\n",
    "    \n",
    "hf = h5py.File(path_dataset + 'AVAdataset_64.hdf5','r')\n",
    "images = hf['images'][:]\n",
    "print images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Pro dataset, build the low quality and high quality hdf5 dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "def processInput(i):\n",
    "    if i % 10e3 == 0:\n",
    "        print i,'/',n_files_Pro,' has been loaded '\n",
    "    img = cv2.imread(path_dataset + img_names[i].strip()).astype(np.float32)\n",
    "    img = cv2.resize(img,(64,64))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.transpose(img,[2,0,1])\n",
    "    img = img / 127.5 - 1.\n",
    "    images[i] = img\n",
    "\n",
    "\n",
    "path_dataset = '/iccluster_data/bjin/ProDataset/'\n",
    "if not os.path.isfile(path_dataset + 'Prodataset_high_64.hdf5'):\n",
    "    print 'generating Pro dataset'\n",
    "    n_files_Pro = int(250e3)\n",
    "    file_metadata = '/iccluster_data/bjin/ProDataset/Images_yfcc100M/Prodataset_yfcc100M_all_filtered_metadata.mat'\n",
    "    temp = loadmat(file_metadata)\n",
    "    img_names = temp['img_names']\n",
    "    scores = temp['aes_scores']\n",
    "    \n",
    "    buffer_name = path_dataset + 'buffter'\n",
    "    images = np.memmap(buffer_name, dtype='float32',shape=(n_files_Pro,3,64,64), mode='w+')\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in range(n_files_Pro))\n",
    "    print images.shape, images.dtype\n",
    "\n",
    "    hf = h5py.File(path_dataset + 'Prodataset_high_64.hdf5','w')\n",
    "    images_hf = hf.create_dataset(\"images\", (n_files_Pro,3,64,64), dtype=np.float32, maxshape=(None,3,64,64))\n",
    "    images_hf[...] = images\n",
    "    hf.close()\n",
    "    \n",
    "hf = h5py.File(path_dataset + 'Prodataset_high_64.hdf5','r')\n",
    "images_high = hf['images'][:]\n",
    "print images_high.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "\n",
    "def processInput(i):\n",
    "    if i % 10e3 == 0:\n",
    "        print i,'/',n_files_Pro,' has been loaded '\n",
    "    img = cv2.imread(path_dataset + img_names[i].strip()).astype(np.float32)\n",
    "    img = cv2.resize(img,(64,64))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img = np.transpose(img,[2,0,1])\n",
    "    img = img / 127.5 - 1.\n",
    "    images[i] = img\n",
    "\n",
    "\n",
    "path_dataset = '/iccluster_data/bjin/ProDataset/'\n",
    "if not os.path.isfile(path_dataset + 'Prodataset_low_64.hdf5'):\n",
    "    print 'generating Pro dataset'\n",
    "    n_files_Pro = int(250e3)\n",
    "    file_metadata = '/iccluster_data/bjin/ProDataset/Images_yfcc100M/Prodataset_yfcc100M_all_filtered_metadata.mat'\n",
    "    temp = loadmat(file_metadata)\n",
    "    img_names = temp['img_names']\n",
    "    scores = temp['aes_scores']\n",
    "    img_names = img_names[scores[0,:]<4]\n",
    "    \n",
    "#     images = np.zeros([n_files_Pro,3,64,64],dtype=np.float32)\n",
    "    buffer_name = path_dataset + 'buffter'\n",
    "    images = np.memmap(buffer_name, dtype='float32',shape=(n_files_Pro,3,64,64), mode='w+')\n",
    "    num_cores = multiprocessing.cpu_count()\n",
    "    Parallel(n_jobs=num_cores)(delayed(processInput)(i) for i in range(n_files_Pro))\n",
    "    print images.shape, images.dtype\n",
    "\n",
    "    hf = h5py.File(path_dataset + 'Prodataset_low_64.hdf5','w')\n",
    "    images_hf = hf.create_dataset(\"images\", (n_files_Pro,3,64,64), dtype=np.float32, maxshape=(None,3,64,64))\n",
    "    images_hf[...] = images\n",
    "    hf.close()\n",
    "    \n",
    "hf = h5py.File(path_dataset + 'Prodataset_low_64.hdf5','r')\n",
    "images_low = hf['images'][:]\n",
    "print images_low.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build and compile theano functions for DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## parameters\n",
    "k = 1            # # of gen updates for each discrim update\n",
    "\n",
    "nc = 3            # # of channels in image\n",
    "nbatch = 128      # # of examples in batch\n",
    "npx = 64          # # of pixels width/height of images\n",
    "nz = 100          # # of dim for Z\n",
    "ngf = 128         # # of gen filters in first conv layer\n",
    "ndf = 128         # # of discrim filters in first conv layer\n",
    "\n",
    "lr = 0.0002       # initial learning rate for adam\n",
    "b1 = 0.5          # momentum term of adam\n",
    "weightdecay = 1e-5         # l2 weight decay\n",
    "batchsize = 128      # # of examples in batch\n",
    "nepoch = 20        # # of epochs for training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COMPILING\n",
      "32.06 seconds to compile theano functions\n"
     ]
    }
   ],
   "source": [
    "## pre-defined layers implemented in theano\n",
    "relu = activations.Rectify()\n",
    "sigmoid = activations.Sigmoid()\n",
    "lrelu = activations.LeakyRectify()\n",
    "tanh = activations.Tanh()\n",
    "bce = T.nnet.binary_crossentropy\n",
    "\n",
    "## initialization methods\n",
    "gifn = inits.Normal(scale=0.02)\n",
    "difn = inits.Normal(scale=0.02)\n",
    "gain_ifn = inits.Normal(loc=1., scale=0.02)\n",
    "bias_ifn = inits.Constant(c=0.)\n",
    "\n",
    "## weights of the generator model\n",
    "# gw  = gifn((nz, ngf*8*4*4), 'gw')\n",
    "# gg = gain_ifn((ngf*8*4*4), 'gg')\n",
    "# gb = bias_ifn((ngf*8*4*4), 'gb')\n",
    "# gw2 = gifn((ngf*8, ngf*4, 5, 5), 'gw2')\n",
    "# gg2 = gain_ifn((ngf*4), 'gg2')\n",
    "# gb2 = bias_ifn((ngf*4), 'gb2')\n",
    "# gw3 = gifn((ngf*4, ngf*2, 5, 5), 'gw3')\n",
    "# gg3 = gain_ifn((ngf*2), 'gg3')\n",
    "# gb3 = bias_ifn((ngf*2), 'gb3')\n",
    "# gw4 = gifn((ngf*2, ngf, 5, 5), 'gw4')\n",
    "# gg4 = gain_ifn((ngf), 'gg4')\n",
    "# gb4 = bias_ifn((ngf), 'gb4')\n",
    "# gwx = gifn((ngf, nc, 5, 5), 'gwx')\n",
    "\n",
    "## define a new generator model which takes an image as conditional input\n",
    "gw = gifn((ngf, nc+1, 5, 5), 'gw')\n",
    "gg = gain_ifn((ngf), 'gg')\n",
    "gb = bias_ifn((ngf), 'gb')\n",
    "gw2 = gifn((ngf*2, ngf, 5, 5), 'gw2')\n",
    "gg2 = gain_ifn((ngf*2), 'gg2')\n",
    "gb2 = bias_ifn((ngf*2), 'gb2')\n",
    "gw3 = gifn((ngf*4, ngf*2, 5, 5), 'gw3')\n",
    "gg3 = gain_ifn((ngf*4), 'gg3')\n",
    "gb3 = bias_ifn((ngf*4), 'gb3')\n",
    "gw4 = gifn((ngf*4, ngf*2, 5, 5), 'gw4')\n",
    "gg4 = gain_ifn((ngf*2), 'gg4')\n",
    "gb4 = bias_ifn((ngf*2), 'gb4')\n",
    "gw5 = gifn((ngf*2, ngf, 5, 5), 'gw5')\n",
    "gg5 = gain_ifn((ngf), 'gg5')\n",
    "gb5 = bias_ifn((ngf), 'gb5')\n",
    "gw6 = gifn((ngf, ngf, 5, 5), 'gw6')\n",
    "gg6 = gain_ifn((ngf), 'gg6')\n",
    "gb6 = bias_ifn((ngf), 'gb6')\n",
    "gw7 = gifn((ngf, ngf+4, 5, 5), 'gw7')\n",
    "gg7 = gain_ifn((ngf), 'gg7')\n",
    "gb7 = bias_ifn((ngf), 'gb7')\n",
    "gwx = gifn((nc, ngf, 5, 5), 'gwx')\n",
    "\n",
    "\n",
    "## weights of the discriminator model\n",
    "dw  = difn((ndf, nc, 5, 5), 'dw')\n",
    "dw2 = difn((ndf*2, ndf, 5, 5), 'dw2')\n",
    "dg2 = gain_ifn((ndf*2), 'dg2')\n",
    "db2 = bias_ifn((ndf*2), 'db2')\n",
    "dw3 = difn((ndf*4, ndf*2, 5, 5), 'dw3')\n",
    "dg3 = gain_ifn((ndf*4), 'dg3')\n",
    "db3 = bias_ifn((ndf*4), 'db3')\n",
    "dw4 = difn((ndf*8, ndf*4, 5, 5), 'dw4')\n",
    "dg4 = gain_ifn((ndf*8), 'dg4')\n",
    "db4 = bias_ifn((ndf*8), 'db4')\n",
    "dwy = difn((ndf*8*4*4, 1), 'dwy')\n",
    "\n",
    "gen_params = [gw, gg, gb, gw2, gg2, gb2, gw3, gg3, gb3, gw4, gg4, gb4, gw5, gg5, gb5, gw6, gg6, gb6, gw7, gg7, gb7, gwx]\n",
    "discrim_params = [dw, dw2, dg2, db2, dw3, dg3, db3, dw4, dg4, db4, dwy]\n",
    "\n",
    "## definition of the generator\n",
    "# def gen(Z, w, g, b, w2, g2, b2, w3, g3, b3, w4, g4, b4, wx):\n",
    "#     h = relu(batchnorm(T.dot(Z, w), g=g, b=b))\n",
    "#     h = h.reshape((h.shape[0], ngf*8, 4, 4))\n",
    "#     h2 = relu(batchnorm(deconv(h, w2, subsample=(2, 2), border_mode=(2, 2)), g=g2, b=b2))\n",
    "#     h3 = relu(batchnorm(deconv(h2, w3, subsample=(2, 2), border_mode=(2, 2)), g=g3, b=b3))\n",
    "#     h4 = relu(batchnorm(deconv(h3, w4, subsample=(2, 2), border_mode=(2, 2)), g=g4, b=b4))\n",
    "#     x = tanh(deconv(h4, wx, subsample=(2, 2), border_mode=(2, 2)))\n",
    "#     return x\n",
    "\n",
    "def gen(Z, w, g, b, w2, g2, b2, w3, g3, b3, w4, g4, b4, w5, g5, b5, w6, g6, b6, w7, g7, b7, wx):\n",
    "    h = relu(batchnorm(dnn_conv(Z, w, subsample=(2, 2), border_mode=(2, 2)), g=g, b=b))\n",
    "    h2 = relu(batchnorm(dnn_conv(h, w2, subsample=(2, 2), border_mode=(2, 2)), g=g2, b=b2))\n",
    "    h3 = relu(batchnorm(dnn_conv(h2, w3, subsample=(2, 2), border_mode=(2, 2)), g=g3, b=b3))\n",
    "    h4 = relu(batchnorm(deconv(h3, w4, subsample=(2, 2), border_mode=(2, 2)), g=g4, b=b4))\n",
    "    h5 = relu(batchnorm(deconv(h4, w5, subsample=(2, 2), border_mode=(2, 2)), g=g5, b=b5))\n",
    "    h6 = relu(batchnorm(deconv(h5, w6, subsample=(2, 2), border_mode=(2, 2)), g=g6, b=b6))\n",
    "    h7 = T.concatenate([h6,Z],axis=1)\n",
    "    h8 = relu(batchnorm(dnn_conv(h7, w7, subsample=(1, 1), border_mode=(2, 2)), g=g7, b=b7))\n",
    "    x = tanh(dnn_conv(h8, wx, subsample=(1, 1), border_mode=(2, 2)))\n",
    "    return x\n",
    "\n",
    "\n",
    "## definiton of the discriminator\n",
    "def discrim(X, w, w2, g2, b2, w3, g3, b3, w4, g4, b4, wy):\n",
    "    h = lrelu(dnn_conv(X, w, subsample=(2, 2), border_mode=(2, 2)))\n",
    "    h2 = lrelu(batchnorm(dnn_conv(h, w2, subsample=(2, 2), border_mode=(2, 2)), g=g2, b=b2))\n",
    "    h3 = lrelu(batchnorm(dnn_conv(h2, w3, subsample=(2, 2), border_mode=(2, 2)), g=g3, b=b3))\n",
    "    h4 = lrelu(batchnorm(dnn_conv(h3, w4, subsample=(2, 2), border_mode=(2, 2)), g=g4, b=b4))\n",
    "    h4 = T.flatten(h4, 2)\n",
    "    y = sigmoid(T.dot(h4, wy))\n",
    "    return y\n",
    "\n",
    "## define the loss\n",
    "X = T.tensor4()\n",
    "Z = T.tensor4()\n",
    "\n",
    "gX = gen(Z, *gen_params)\n",
    "\n",
    "p_real = discrim(X, *discrim_params)\n",
    "p_gen = discrim(gX, *discrim_params)\n",
    "\n",
    "d_cost_real = bce(p_real, T.ones(p_real.shape)).mean()\n",
    "d_cost_gen = bce(p_gen, T.zeros(p_gen.shape)).mean()\n",
    "g_cost_d = bce(p_gen, T.ones(p_gen.shape)).mean()\n",
    "\n",
    "d_acc_real = T.mean(p_real > 0.5)\n",
    "d_acc_gen = T.mean(p_gen < 0.5)\n",
    "d_acc = T.mean(T.concatenate([(p_real > 0.5),(p_gen<0.5)],axis=0))\n",
    "g_acc_d = T.mean(p_gen>0.5)\n",
    "\n",
    "d_cost = d_cost_real + d_cost_gen\n",
    "g_cost = g_cost_d\n",
    "g_acc = g_acc_d\n",
    "\n",
    "cost = [g_cost, d_cost, g_cost_d, d_cost_real, d_cost_gen]\n",
    "acc = [g_acc, d_acc, g_acc_d, d_acc_real, d_acc_gen]\n",
    "\n",
    "lrt = sharedX(lr)\n",
    "d_updater = updates.Adam(lr=lrt, b1=b1, regularizer=updates.Regularizer(l2=weightdecay))\n",
    "g_updater = updates.Adam(lr=lrt, b1=b1, regularizer=updates.Regularizer(l2=weightdecay))\n",
    "d_updates = d_updater(discrim_params, d_cost)\n",
    "g_updates = g_updater(gen_params, g_cost)\n",
    "# updates = d_updates + g_updates\n",
    "\n",
    "print 'COMPILING'\n",
    "t = time.time()\n",
    "_train_g = theano.function([X, Z], cost + acc, updates=g_updates)\n",
    "_train_d = theano.function([X, Z], cost + acc, updates=d_updates)\n",
    "_gen = theano.function([Z], gX)\n",
    "print '%.2f seconds to compile theano functions'%(time.time()-t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_high = np.zeros((2000,3,64,64)).astype(np.float32)\n",
    "images_low = np.zeros((2000,3,64,64)).astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1\n",
      " 384/1920 [=====>........................] - ETA: 11s - g_loss: 16.7246 - g_acc: 0.0000e+00 - d_loss: 9.2148e-06 - d_acc: 1.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-98fb24ab256a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m             \u001b[0mmylogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_train_d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch_high\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_batch_low_n\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mmylogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_train_g\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_batch_high\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimage_batch_low_n\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[0mmycost\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmylogs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/iccluster_data/bjin/anaconda2/envs/keras1/lib/python2.7/site-packages/theano/compile/function_module.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    860\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 862\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[1;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    863\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    864\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m/iccluster_data/bjin/anaconda2/envs/keras1/lib/python2.7/site-packages/theano/gof/op.pyc\u001b[0m in \u001b[0;36mrval\u001b[1;34m(p, i, o, n)\u001b[0m\n\u001b[0;32m    905\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNoParams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    906\u001b[0m             \u001b[1;31m# default arguments are stored in the closure of `rval`\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 907\u001b[1;33m             \u001b[1;32mdef\u001b[0m \u001b[0mrval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_input_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode_output_storage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    908\u001b[0m                 \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mo\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    909\u001b[0m                 \u001b[1;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator()\n",
    "path_results = '/iccluster_data/bjin/Dcgan/results/Aug/'\n",
    "## start training\n",
    "for epoch in range(nepoch):\n",
    "    batch_count = 0\n",
    "    print 'epoch: ', epoch + 1\n",
    "    \n",
    "    progbar = generic_utils.Progbar(np.floor(len(images_high)/batchsize) * batchsize)\n",
    "    for batch_count in range(int(np.floor(len(images_high)/batchsize))):\n",
    "        image_batch_high = images_high[batch_count*batchsize:(batch_count+1)*batchsize]\n",
    "        image_batch_low = images_low[batch_count*batchsize:(batch_count+1)*batchsize]\n",
    "        noise = np.random.uniform(-1,1,(batchsize, 1, image_batch_low.shape[2], image_batch_low.shape[3])).astype(np.float32)\n",
    "        image_batch_low_n = np.concatenate([image_batch_low, noise],axis = 1)\n",
    "        \n",
    "        if batch_count % (k+1) == 0:\n",
    "            mylogs = _train_d(image_batch_high.astype(np.float32), image_batch_low_n.astype(np.float32))\n",
    "        else:\n",
    "            mylogs = _train_g(image_batch_high.astype(np.float32), image_batch_low_n.astype(np.float32))\n",
    "\n",
    "        mycost = mylogs[0:5]\n",
    "        myacc = mylogs[5:10]    \n",
    "        progbar.add(image_batch_high.shape[0], values=[(\"g_loss\", mycost[0]),(\"g_acc\", myacc[0]),('d_loss',mycost[1]),('d_acc',myacc[1])])\n",
    "\n",
    "        if (batch_count+1) % 100 == 0:\n",
    "            print ''\n",
    "            print 'loss (g_cost, d_cost, g_cost_d, d_cost_real, d_cost_gen):'\n",
    "            print mycost\n",
    "            print 'accuracy (g_acc, d_acc, g_acc_d, d_acc_real, d_acc_gen):'\n",
    "            print myacc\n",
    "            print 'visualize generated samples'\n",
    "            # 'Generating images..'\n",
    "            generated_images = _gen(image_batch_low)\n",
    "            figname = path_results + str(epoch+1) + '_' + str(batch_count) +'.pdf'\n",
    "            visualizeimages(generated_images,figname,showflag=True)\n",
    "            visualizeimages(image_batch_low,showflag=True)\n",
    "            visualizeimages(image_batch_high,showflag=True)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 4, 64, 64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_batch_low_n.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
